---
tags: [@computing-performance]
title: Holistic performance evaluation
---

- Performance measurements are suspect because they highlight specific, hand-picked optimizations.
  This seems likelier when you consider that measurements usually come at the end of a project lifecycle, and can be used to advertise.
- A better approach to evaluating performance is a whole understanding of the system, its behavior under specific conditions.
- Link a code change to a change in resource usage (e.g. number of instructions executed, cache misses).
  Link a change in resource usage to change in performance measurement (e.g. table insertion throughput).
- Develop and lean on automation for measurement, from the beginning of your project.
  This includes scripts to run the test harness, and scripts to plot the results.
- Evaluate performance across a variety of workloads, of system configurations.
  This makes trade-offs more apparent, or can show that an algorithm is optimal in all cases.

## Links
- [Report everything about performance from what you can measure](202004021442.md)
- [Performance beyond timing](202004021235.md)
- [Unit test your performance harness](202004021234.md)
- [Performance testing environments are constrained cases of production-like environments](202004021236.md)

## References
- [Harris, Tim. "Five ways not to fool yourself. or: designing experiments for understanding performance."](refs/harris-tim_five-ways.pdf)
